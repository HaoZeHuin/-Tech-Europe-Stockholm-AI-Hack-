# System Overview

## ğŸ¯ Current Project Status

Jarvis-in-a-Box is a **real-time voice-first AI assistant** powered by OpenAI's Realtime API. The current implementation focuses on seamless voice interaction with tool execution capabilities.

## ğŸ—ï¸ Current Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  JARVIS VOICE ASSISTANT                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend (React + Vite)     â”‚  Backend (FastAPI + Python)  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Voice Interface         â”‚  â”‚  â”‚ Gateway Service         â”‚ â”‚
â”‚  â”‚ - Push-to-Talk UI       â”‚â—„â”€â”¼â”€â”€â”¤ - WebSocket Server      â”‚ â”‚
â”‚  â”‚ - Audio Processing      â”‚  â”‚  â”‚ - OpenAI Integration    â”‚ â”‚
â”‚  â”‚ - Jitter Buffer         â”‚  â”‚  â”‚ - Session Management    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Audio Pipeline          â”‚  â”‚  â”‚ OpenAI Realtime API     â”‚ â”‚
â”‚  â”‚ - AudioWorklet          â”‚  â”‚  â”‚ - Voice Processing      â”‚ â”‚
â”‚  â”‚ - PCM16 @ 24kHz         â”‚â—„â”€â”¼â”€â”€â”¤ - Tool Execution        â”‚ â”‚
â”‚  â”‚ - Real-time Streaming   â”‚  â”‚  â”‚ - Response Generation   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technology Stack

### Frontend
- **React 18** with TypeScript
- **Vite** for fast development and building
- **Tailwind CSS** for styling
- **WebSocket** for real-time communication
- **AudioWorklet** for microphone processing

### Backend
- **FastAPI** Python web framework
- **Uvicorn** ASGI server
- **OpenAI Agents SDK** for Realtime API integration
- **WebSockets** for bidirectional communication

### Audio Processing
- **Format**: PCM16 mono audio
- **Sample Rate**: 24kHz input and output
- **Streaming**: Real-time bidirectional audio
- **Buffering**: Jitter buffer for smooth playback

## ğŸ¤ Voice Interaction Flow

### 1. User Interaction
```
User clicks voice button â†’ Microphone activates â†’ Audio capture begins
```

### 2. Audio Processing
```
AudioWorklet captures â†’ Convert to PCM16 â†’ Base64 encode â†’ WebSocket send
```

### 3. Backend Processing
```
WebSocket receive â†’ Decode audio â†’ Forward to OpenAI â†’ Process response
```

### 4. Response Playback
```
OpenAI audio response â†’ Jitter buffer â†’ Audio scheduling â†’ Speaker output
```

## ğŸ“¡ Communication Protocol

### WebSocket Events

**Frontend â†’ Backend:**
- `input_audio_buffer.append` - Send audio data to OpenAI
- `input_audio_buffer.commit` - Commit audio buffer for processing

**Backend â†’ Frontend:**
- `response.audio.delta` - Audio response chunks from OpenAI
- `response.audio.done` - Audio response completed
- `session.created` - Session established
- `error` - Error messages

### Audio Data Format
```json
{
  "type": "input_audio_buffer.append",
  "audio": "base64-encoded-pcm16-audio-data"
}
```

## ğŸ› ï¸ Key Components

### Frontend Components
- **RealtimeVoiceInterface.tsx**: Main voice interaction component
- **audio-processor.js**: AudioWorklet for microphone processing
- **Index.tsx**: Main page layout with voice interface

### Backend Components
- **main.py**: FastAPI WebSocket server with OpenAI integration
- **jarvis_agent.py**: Jarvis agent configuration
- **prompts.py**: System prompts and personality

### Configuration
- **Model Settings**: Voice model, audio format, sample rates
- **System Prompts**: Jarvis personality and behavior
- **Environment**: API keys and service configuration

## ğŸ”„ Session Lifecycle

### 1. Connection
```python
# Frontend connects to WebSocket
ws = new WebSocket('ws://localhost:8000/api/realtime/session_123')

# Backend establishes OpenAI Realtime session
session = await session_context.__aenter__()
```

### 2. Audio Streaming
```python
# Continuous bidirectional audio streaming
Frontend â†â†’ Backend â†â†’ OpenAI Realtime API
```

### 3. Cleanup
```python
# Session cleanup on disconnect
await session_context.__aexit__()
```

## ğŸ¯ Current Capabilities

### âœ… Working Features
- **Real-time voice interaction** with low latency
- **Push-to-talk interface** with visual feedback
- **Audio processing pipeline** at 24kHz PCM16
- **WebSocket communication** with OpenAI
- **Jitter buffer** for smooth audio playback
- **Session management** with proper cleanup

### ğŸš§ In Development
- **Tool system expansion** for more voice commands
- **Enhanced error handling** and recovery
- **Audio quality optimization**
- **Additional voice commands and capabilities**

## ğŸ“Š Performance Characteristics

### Latency
- **Audio capture**: ~20ms (AudioWorklet buffer)
- **Network transmission**: ~10-50ms (depends on connection)
- **OpenAI processing**: ~200-500ms (voice-to-voice)
- **Total round-trip**: ~250-600ms

### Audio Quality
- **Sample rate**: 24kHz (high quality)
- **Bit depth**: 16-bit PCM
- **Channels**: Mono
- **Buffering**: 80ms jitter buffer for smoothness

## ğŸ”’ Security & Privacy

### Current Implementation
- **API key security**: Stored in environment variables
- **Session isolation**: Each WebSocket connection is isolated
- **Input validation**: WebSocket message validation
- **Error handling**: Safe error responses without data leakage

### Planned Enhancements
- **Rate limiting** for API calls
- **User authentication** for multi-user support
- **Audit logging** for voice interactions
- **Data retention policies**

## ğŸš€ Development Status

### Current Phase: **MVP Voice Assistant**
- Core voice interaction working
- Real-time audio streaming implemented
- Basic tool execution framework
- Development-ready setup

### Next Phase: **Tool System Expansion**
- Weather, calendar, and note-taking tools
- Enhanced voice command recognition
- Multi-modal interaction support
- Production deployment preparation

---

**Ready for hackathon development! The foundation is solid and extensible.** ğŸ¯